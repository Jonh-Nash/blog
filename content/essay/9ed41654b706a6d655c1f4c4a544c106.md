---
title: "今さらだけどKaggleのLLM講座を全部読んだよ。"
created_date: "2025-03-20 17:46:41"
updated_date: "2025-03-20 17:46:41"
tags: []
---

## 感想やメモ

Kaggle の LLM 講座読んだ。包括的にまとまっていてよかった。
以下は学んだこと

- 基本
  - ML の基本はパラメータの学習 → それを使って推論
  - LLM も同じ。Transformer の学習 →FineTune → 推論
  - 感想: 上記は当たり前なんだけど、LLM って聞くと身構えちゃうよね。でも、普通の ML と同じように精度を上げていくんだよね
- Agent

  - "Extention": LLM が直接操作するもの。
    - 感想: はやりの MCP とかはここのインターフェースを整理するものの認識
  - Functions: なんかよく分からんかった w
    - 感想: LLM からの出力を強制させるものっていう認識でいいのかな
  - 感想: どっかでも書いたけど Orchestrator が頭良くないとダメなんだよな。

- ドメイン特化

  - 学習 → 継続事前学習 → 教師あり FineTune → 評価 + FewShot のプロンプトとか RAG を組み合わて最新の情報に対して対応
  - それを Agent の思考フレームワークにのせて、SQL を叩けるようにして Tools を作ったり、それに合わせた FineTune したり
  - 感想: これも当たり前の流れなんだけど、整理されてよかった

- MLOps
  - 感想: これはよく読む。さっと読んだ感じとても大事なことが書いてある
