<!DOCTYPE html><html lang="ja"> <head><meta charset="utf-8"><title>20250602</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml"></head> <body> <header><a href="/blog/">Home</a></header> <main>  <article> <h1 id="20250602">2025/06/02</h1>
<h2 id="why-do-lawyers-keep-using-chatgpt">Why do lawyers keep using ChatGPT?</h2>
<h3 id="リンク">リンク</h3>
<ul>
<li><a href="https://www.theverge.com/policy/677373/lawyers-chatgpt-hallucinations-ai">https://www.theverge.com/policy/677373/lawyers-chatgpt-hallucinations-ai</a></li>
</ul>
<h3 id="英語要約">英語要約</h3>
<ul>
<li>Despite publicized sanctions for filing AI-fabricated citations, many attorneys still lean on ChatGPT-style tools to draft and research.</li>
<li>Drivers: crushing deadlines and AI features embedded in Westlaw/Lexis. Some lawyers misperceive LLMs as <em>super search engines</em>, ignoring hallucination risk.</li>
<li>2024 Thomson Reuters survey: <strong>63 %</strong> of lawyers tried generative AI; <strong>12 %</strong> use it routinely.</li>
<li>Experts urge verification workflows; ABA stresses tech-competence and confidentiality. :contentReference[oaicite:2]{index=2}</li>
</ul>
<h3 id="日本語翻訳">日本語翻訳</h3>
<ul>
<li>偽判例を提出して処分を受けた事例が続く中でも、弁護士は ChatGPT 系ツールで起案・調査を続けている。</li>
<li>背景は過密な締切と、Westlaw/Lexis に組み込まれた AI 機能。LLM を「超検索エンジン」と誤認し、幻覚リスクを軽視する例も。</li>
<li>2024 年の調査では弁護士の 63％が生成 AI を試用、12％が常用。</li>
<li>専門家は検証プロセスの徹底を推奨し、米国弁護士会は技術習熟と秘匿義務への注意を呼びかける。</li>
</ul>
<h3 id="感想">感想</h3>
<p>まあ仕組み上ハルシネーションは起きるもので、僕はソフトウェアエンジニアとしてはジュニアレベルのコーディングが得意な人として扱っている。
しばらくはそういう付き合いになりそう。</p>
<h2 id="chinese-ai-start-up-deepseek-pushes-us-rivals-with-r1-0528-model-upgrade">Chinese AI start-up DeepSeek pushes US rivals with R1-0528 model upgrade</h2>
<h3 id="リンク-1">リンク</h3>
<ul>
<li><a href="https://www.reuters.com/world/china/chinas-deepseek-releases-an-update-its-r1-reasoning-model-2025-05-29/">https://www.reuters.com/world/china/chinas-deepseek-releases-an-update-its-r1-reasoning-model-2025-05-29/</a></li>
</ul>
<h3 id="英語要約-1">英語要約</h3>
<ul>
<li><strong>DeepSeek</strong> released <strong>R1-0528</strong>, cutting hallucinations ~45–50 % and boosting math/coding benchmarks to near-parity with OpenAI “o3” and Google Gemini 2.5.</li>
<li>Showcased <em>distilling</em> R1 reasoning into Alibaba’s Qwen-3 8B, beating the original by >10 %.</li>
<li>U.S. giants responded with cheaper API tiers and lightweight models; Chinese peers rushed upgrades.</li>
<li>Underscores global competition even under chip-export curbs. :contentReference[oaicite:5]{index=5}</li>
</ul>
<h3 id="日本語翻訳-1">日本語翻訳</h3>
<ul>
<li><strong>DeepSeek</strong> は <strong>R1-0528</strong> を公開、幻覚率を約 45–50％削減し、数学・コーディング性能で OpenAI「o3」や Google Gemini 2.5 に迫る。</li>
<li>推論過程を <strong>知識蒸留</strong> し、Alibaba Qwen-3 8B を 10％以上上回る小型モデルを生成。</li>
<li>米大手は API 値下げや軽量モデルで対抗、中国勢もアップグレードを急ぐ。</li>
<li>半導体規制下でも競争が加速することを示す。</li>
</ul>
<h3 id="感想-1">感想</h3>
<p>R2 のリリースではなかったものの、DeepSeek のモデルアップデートは注目に値するので書いておく。</p> </article>  </main> <footer>© 2025 justy's blog</footer> </body></html>