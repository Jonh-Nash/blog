<!DOCTYPE html><html lang="ja"> <head><meta charset="utf-8"><title>20250817</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml"></head> <body> <header><a href="/blog/">Home</a></header> <main>  <article> <h1 id="20250817">2025/08/17</h1>
<h2 id="chatgpts-model-picker-is-back-and-its-complicated">ChatGPT’s model picker is back, and it’s complicated</h2>
<h3 id="リンク">リンク</h3>
<ul>
<li><a href="https://techcrunch.com/2025/08/12/chatgpts-model-picker-is-back-and-its-complicated/">https://techcrunch.com/2025/08/12/chatgpts-model-picker-is-back-and-its-complicated/</a></li>
</ul>
<h3 id="英語要約">英語要約</h3>
<p>Despite GPT-5’s unified promise, OpenAI reintroduced a model picker with Auto/Fast/Thinking modes and restored access to legacy models. The change reflects strong user preferences and the challenge of routing. GPT-5’s rollout highlighted how model “personality” affects adoption.</p>
<h3 id="日本語翻訳">日本語翻訳</h3>
<p>統一モデルの方針にもかかわらず、Auto／Fast／Thinkingのモード選択が復活し、旧モデルも利用可能に。強いユーザー嗜好とルーティングの難しさが浮き彫りに。モデルの“人格”が採用に影響することが示された。</p>
<h3 id="感想">感想</h3>
<p>簡単なタスクを推論しすぎで間違うこともありそうだったから、自分で選べるのはありがたい。
自分はタスクの声質とか難易度によって使い分けている。まあ将来的にはルーターにお任せした方が適切にモデル選択できるようになるだろうけどね。</p>
<h2 id="microsoft-brings-openais-smallest-open-model-to-windows-users">Microsoft brings OpenAI’s smallest open model to Windows users</h2>
<h3 id="リンク-1">リンク</h3>
<ul>
<li><a href="https://techcrunch.com/2025/08/06/microsoft-brings-openais-smallest-open-model-to-windows-users/">https://techcrunch.com/2025/08/06/microsoft-brings-openais-smallest-open-model-to-windows-users/</a></li>
</ul>
<h3 id="英語要約-1">英語要約</h3>
<p>Microsoft is shipping OpenAI’s gpt-oss-20B through Windows AI Foundry, enabling local agentic tasks on consumer PCs with ~16GB VRAM. It targets tool-using assistants and edge scenarios. Both gpt-oss-20B and 120B also land on Azure AI Foundry.</p>
<h3 id="日本語翻訳-1">日本語翻訳</h3>
<p>Microsoftはgpt-oss-20BをWindows AI Foundryで配布し、16GB級GPUのPCでローカル推論とエージェント処理を実現。エッジやツール実行タスクを狙い、Azure側でも取り扱いを開始。</p>
<h3 id="感想-1">感想</h3>
<p>まず、PC にローカルLLMが組み込まれてOSレベルで体験が変わっていき、次にスマホに来ると思う。エッジデバイス推論勉強するかなぁ。</p>
<h2 id="anthropics-claude-ai-model-can-now-handle-longer-prompts">Anthropic’s Claude AI model can now handle longer prompts</h2>
<h3 id="リンク-2">リンク</h3>
<ul>
<li><a href="https://techcrunch.com/2025/08/12/anthropics-claude-ai-model-can-now-handle-longer-prompts/">https://techcrunch.com/2025/08/12/anthropics-claude-ai-model-can-now-handle-longer-prompts/</a></li>
</ul>
<h3 id="英語要約-2">英語要約</h3>
<p>Anthropic expanded Claude’s context window to handle much longer inputs, enhancing code and document workflows. The update positions Claude competitively for enterprise knowledge tasks. It complements Anthropic’s policy and government access moves.</p>
<h3 id="日本語翻訳-2">日本語翻訳</h3>
<p>Claudeの文脈長が拡張され、長文ドキュメントやコード処理が強化。エンタープライズの知識業務での競争力を高め、同社の政策・公共分野戦略と相乗する。</p>
<h3 id="感想-2">感想</h3>
<p>20万→100万に(ちなみにGPT-5は40万らしい)。
簡易な RAG だったらコンテキストに載せるのが良さそうだなぁ。</p> </article>  </main> <footer>© 2025 justy's blog</footer> </body></html>