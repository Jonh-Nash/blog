<!DOCTYPE html><html lang="ja"> <head><meta charset="utf-8"><title>20250505</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml"></head> <body> <header><a href="/blog/">Home</a></header> <main>  <article> <h1 id="20250505">2025/05/05</h1>
<h2 id="microsoft-ships-phi-4-reasoning-small-models">Microsoft ships “Phi 4-Reasoning” small models</h2>
<h3 id="リンク">リンク</h3>
<ul>
<li><a href="https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/">https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/</a></li>
</ul>
<h3 id="英語要約">英語要約</h3>
<p>Microsoft introduced three <strong>Phi 4-Reasoning</strong> variants (3.8 B, 14 B, 30 B). Using synthetic DeepSeek R1 tasks plus RL fine-tuning, they match 70 B-parameter models on math, code and planning while remaining free for research and edge deployment.</p>
<h3 id="日本語翻訳">日本語翻訳</h3>
<p>Microsoft は <strong>Phi 4-Reasoning</strong>（3.8 B・14 B・30 B）を公開。DeepSeek 合成課題＋ RL 微調整で 70 B 級モデルに並ぶ推論力を示し、研究・エッジ用途へ無償提供する。</p>
<h3 id="感想">感想</h3>
<p>Microsoft はまだ OSS モデル作ってたんだ。
大量のリソースが必要な大型モデルは OpenAI に任せて、自分たちは小型モデルを OSS で作ってクライアント向けに FineTune していく戦略かな。</p>
<p>小型 OSS モデルの選択肢多いんだけど、ここら辺は Kaggle とかで取捨選択されていくんだろうな。今の所肌感覚的には Qwen が強そう。</p>
<h2 id="deepseek-releases-deepseek-prover-v2">DeepSeek releases “DeepSeek-Prover-V2”</h2>
<h3 id="リンク-1">リンク</h3>
<ul>
<li><a href="https://medium.com/data-science-in-your-pocket/deepseek-prover-v2-deepseeks-new-model-for-maths-d1f85414bc7b">https://medium.com/data-science-in-your-pocket/deepseek-prover-v2-deepseeks-new-model-for-maths-d1f85414bc7b</a></li>
</ul>
<h3 id="英語要約-1">英語要約</h3>
<p>DeepSeek launched <strong>DeepSeek-Prover-V2</strong> (7 B / 67 B), a Lean 4 theorem-proving LLM. Recursive proof synthesis and RL on synthetic data push MiniF2F accuracy to 88.9 % and solve 49 PutnamBench problems.</p>
<h3 id="日本語翻訳-1">日本語翻訳</h3>
<p>DeepSeek は Lean 4 用定理証明 LLM <strong>DeepSeek-Prover-V2</strong>（7 B / 67 B）を公開。再帰的証明生成と合成データ＋ RL により MiniF2F 88.9 %、PutnamBench 49 問を達成。</p>
<h3 id="感想-1">感想</h3>
<p>数学証明用の Lean4 っていう言語があるらしい。それを使ってるんだって。
論理の確からしさを厳密に検証できるようになるって感じかな。将来的に SLA とかに使われたりして。</p>
<hr>
<h2 id="amazon-debuts-1-m-token-nova-premier">Amazon debuts 1-M-token “Nova Premier”</h2>
<h3 id="リンク-2">リンク</h3>
<ul>
<li><a href="https://aws.amazon.com/blogs/aws/amazon-nova-premier-our-most-capable-model-for-complex-tasks-and-teacher-for-model-distillation/">https://aws.amazon.com/blogs/aws/amazon-nova-premier-our-most-capable-model-for-complex-tasks-and-teacher-for-model-distillation/</a></li>
</ul>
<h3 id="英語要約-2">英語要約</h3>
<p>Amazon unveiled <strong>Nova Premier</strong>, a foundation model with a 1-million token window covering text, images and video. Benchmarks show top retrieval and multimodal reasoning. It ships via Bedrock, with distilled variants planned.</p>
<h3 id="日本語翻訳-2">日本語翻訳</h3>
<p>Amazon は <strong>Nova Premier</strong> を発表。テキスト・画像・動画を 100 万トークン一括処理できるモデルで、検索・マルチモーダル推論ベンチで高得点。Bedrock で提供し、小型蒸留版も準備中。</p>
<h3 id="感想-2">感想</h3>
<p>ロングコンテキスト系。Amazon も競争に加わりたいみたい。
MS みたいに OpenAI に任せるのではなくて自前でやっていくのだろうか。そのうち DeepSeek や Qwen とかと手を組み出しても驚きはしない。</p>
<h2 id="openai-rolls-back-gpt-4o-update-over-sycophancy">OpenAI rolls back GPT-4o update over sycophancy</h2>
<h3 id="リンク-3">リンク</h3>
<ul>
<li><a href="https://openai.com/blog/gpt-4o-sycophancy-update-roll-back">https://openai.com/blog/gpt-4o-sycophancy-update-roll-back</a></li>
</ul>
<h3 id="英語要約-3">英語要約</h3>
<p>OpenAI admitted a 25 Apr update made GPT-4o overly flattering toward users. The company reverted to an earlier version on 28 Apr and pledged stricter evaluation and safety checks.</p>
<h3 id="日本語翻訳-3">日本語翻訳</h3>
<p>OpenAI は 4 月 25 日の更新で GPT-4o が過度に迎合的になったと認め、28 日に旧版へロールバック。評価プロセスと安全チェックを強化すると説明した。</p>
<h3 id="感想-3">感想</h3>
<p>ここら辺の使用感はどうしてもベンチマークじゃ測れないよね。
正直他のモデルとかでもベンチマークが高いからといって、日常仕事で使えるかはまた別の話だと思う。</p>
<h2 id="dangerous-nonsense-ai-authored-books-about-adhd-flood-amazon">“Dangerous nonsense”: AI-authored books about ADHD flood Amazon</h2>
<h3 id="リンク-4">リンク</h3>
<ul>
<li><a href="https://www.theguardian.com/technology/2025/may/04/dangerous-nonsense-ai-authored-books-about-adhd-for-sale-on-amazon">https://www.theguardian.com/technology/2025/may/04/dangerous-nonsense-ai-authored-books-about-adhd-for-sale-on-amazon</a></li>
</ul>
<h3 id="英語要約-4">英語要約</h3>
<p>The Guardian reports dozens of ADHD self-help e-books on Amazon seemingly written entirely by ChatGPT. Experts warn they contain medically dangerous misinformation, exposing the void of publishing guardrails for AI-generated content.</p>
<h3 id="日本語翻訳-4">日本語翻訳</h3>
<p>Amazon の Kindle ストアに、ChatGPT で大量生成されたとみられる ADHD ハウツー本が多数並び、医学的に危険な誤情報も含むと The Guardian が報道。出版における AI 表示義務や責任枠組みの欠如が浮き彫りになった。</p>
<h3 id="感想-4">感想</h3>
<p>最近よく聞く”ガードレール”が必要ですな。</p>
<h2 id="cardinal-criticises-trumps-ai-generated-pope-trump-image">Cardinal criticises Trump’s AI-generated “Pope Trump” image</h2>
<h3 id="リンク-5">リンク</h3>
<ul>
<li><a href="https://www.reuters.com/world/us/new-york-cardinal-says-trump-ai-pope-image-wasnt-good-2025-05-04/">https://www.reuters.com/world/us/new-york-cardinal-says-trump-ai-pope-image-wasnt-good-2025-05-04/</a></li>
</ul>
<h3 id="英語要約-5">英語要約</h3>
<p>Donald Trump posted an AI image of himself as the Pope on Truth Social. New York Cardinal Timothy Dolan called it “brutta figura,” underscoring how generative imagery can offend religious communities and amplify misinformation.</p>
<h3 id="日本語翻訳-5">日本語翻訳</h3>
<p>トランプ氏が自らを法王姿にした AI 画像を Truth Social に投稿。ニューヨーク大司教ドーラン枢機卿は「みっともない」と批判し、生成画像が宗教的感情を傷つける危険性を示した。</p>
<h3 id="感想-5">感想</h3>
<p>こういう文化的背景とかを AI が考慮できるかって結構難しい気がする。時代で全然変わるし。
教養として学んどく必要があるなと思った。</p>
<h2 id="nvidia-stock-seen-rebounding-as-big-tech-pours-200-bn-into-ai">Nvidia stock seen rebounding as Big Tech pours $200 bn into AI</h2>
<h3 id="リンク-6">リンク</h3>
<ul>
<li><a href="https://www.fingerlakes1.com/2025/05/04/nvidia-meta-amazon-google-ai-stock-outlook-2025/">https://www.fingerlakes1.com/2025/05/04/nvidia-meta-amazon-google-ai-stock-outlook-2025/</a></li>
</ul>
<h3 id="英語要約-6">英語要約</h3>
<p>FingerLakes1 cites analysts predicting Nvidia shares will rebound as Meta, Amazon and Alphabet plan to spend over $200 billion on AI infrastructure in 2025, boosting GPU demand.</p>
<h3 id="日本語翻訳-6">日本語翻訳</h3>
<p>Meta・Amazon・Alphabet が 2025 年だけで AI インフラに 2000 億ドル超を投資予定とされ、GPU 需要急増で Nvidia 株の反騰が見込まれると FingerLakes1 が報道。</p>
<h3 id="感想-6">感想</h3>
<blockquote>
<p>ハードウェア層では <strong>寡占＋フルスタック化</strong> が進む。GPU 供給網を握る企業は “石油メジャー” の再来 ── だがリスクは <strong>規制と中古市場</strong> にある。</p>
</blockquote>
<p>o3 に感想書かせたら上の文章を出してきた。規制はなるほど。中古市場はどういうことだろうと思って聞いて見たら以下回答。</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>1. 寡占＋フルスタック化</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    少数企業がチップからソフトウェア・クラウドまで垂直統合。</span></span>
<span class="line"><span>    新規参入が難しく、収益率（マージン）が高止まりしやすい。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>2. “石油メジャー”の再来</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    AI = 21世紀のエネルギー。GPU覇者は産業の“ライフライン”を支配し、交渉力とリース料（クラウド料金）で巨大な経済的レンティア（地代収入）を得る。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>3. しかし二大リスクが潜む</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    規制：独禁・安全保障・環境の各方面から締め付けが来れば、強すぎる価格決定権は一気に揺らぐ。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    中古市場：次世代GPU・ASICが急速に進化し、旧モデルが二次市場に流れるサイクルが短くなると、需給バランスが崩れて値崩れし、寡占プレイヤーの“石油”が一転して“コモディティ”化する可能性をはらむ。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>要するに、今は圧倒的支配に見えるGPU王者も、外部要因（政府と市場循環）次第では地位が急速に弱まる、という警鐘を込めた一文です。</span></span></code></pre> </article>  </main> <footer>© 2025 justy's blog</footer> </body></html>