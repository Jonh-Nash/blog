<!DOCTYPE html><html lang="ja"> <head><meta charset="utf-8"><title>20250620</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml"></head> <body> <header><a href="/blog/">Home</a></header> <main>  <article> <h1 id="20250620">2025/06/20</h1>
<h2 id="google-is-using-youtube-videos-to-train-its-ai-models-creators-didnt-even-know">Google is using YouTube videos to train its AI models, creators didn’t even know</h2>
<h3 id="リンク">リンク</h3>
<ul>
<li><a href="https://www.cnbc.com/2025/06/19/google-youtube-ai-training-veo-3.html">https://www.cnbc.com/2025/06/19/google-youtube-ai-training-veo-3.html</a></li>
</ul>
<h3 id="英語要約">英語要約</h3>
<p>CNBC reports that Google is tapping its vault of roughly 20 billion YouTube videos to train state-of-the-art multimodal models such as <strong>Gemini</strong> and the video-generation model <strong>Veo 3</strong>. A YouTube spokesperson confirmed the practice, noting that only “a subset” of videos is used under existing agreements and guardrails. Critics say the move raises copyright and consent questions for creators whose content now powers Google’s AI ambitions. ([tech.slashdot.org][1])</p>
<h3 id="日本語翻訳">日本語翻訳</h3>
<p>Google は、約 200 億本の YouTube 動画を用いて最新 AI モデル（Gemini や Veo 3 など）を学習させていると CNBC が報じた。YouTube 広報は「動画の一部のみを契約に基づき使用している」と説明しているが、クリエイターからは著作権や同意を巡る懸念が噴出している。</p>
<h3 id="感想">感想</h3>
<p>もし仮に Youtube を学習データに使えるとしたら、こんなに良いプラットフォームはないよね。</p>
<h2 id="googles-ai-mode-can-now-have-back-and-forth-voice-conversations">Google’s AI Mode can now have back-and-forth voice conversations</h2>
<h3 id="リンク-1">リンク</h3>
<ul>
<li><a href="https://techcrunch.com/2025/06/18/googles-ai-mode-can-now-have-back-and-forth-voice-conversations/">https://techcrunch.com/2025/06/18/googles-ai-mode-can-now-have-back-and-forth-voice-conversations/</a></li>
</ul>
<h3 id="英語要約-1">英語要約</h3>
<p>Google added <strong>Search Live</strong> voice chat to its experimental AI Mode in the Google app. Users speak questions, receive spoken AI answers, and can follow up hands-free while links appear for deeper reading. The system runs a custom <strong>Gemini</strong> model and keeps Google Search safety/quality filters. ([techcrunch.com][5])</p>
<h3 id="日本語翻訳-1">日本語翻訳</h3>
<p>Google は、AI Mode に音声対話機能「Search Live」を導入。ユーザーは口頭で質問し、AI の音声回答を聞きながら追質問も可能。背後では Gemini ベースのカスタムモデルが動作し、検索品質・安全基準を維持する。</p>
<h3 id="感想-1">感想</h3>
<p>音声インターフェースというかライブ感というか、最近 Google はそういうのを大事にしているな。
どのくらい遅延なく会話できるんだろう？まあ調べ物だから遅延があってもいいんだろうけど、AI との会話での現時点でのネックは「遅延」だと思う。
ここら辺でちょっと遊んでみようかな。</p> </article>  </main> <footer>© 2025 justy's blog</footer> </body></html>