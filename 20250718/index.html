<!DOCTYPE html><html lang="ja"> <head><meta charset="utf-8"><title>20250718</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml"></head> <body> <header><a href="/blog/">Home</a></header> <main>  <article> <h1 id="20250717">2025/07/17</h1>
<h2 id="openai-launches-a-general-purpose-agent-in-chatgpt-techcrunch">OpenAI launches a general purpose agent in ChatGPT (TechCrunch)</h2>
<h3 id="リンク">リンク</h3>
<ul>
<li><a href="https://techcrunch.com/2025/07/17/openai-launches-a-general-purpose-agent-in-chatgpt/">https://techcrunch.com/2025/07/17/openai-launches-a-general-purpose-agent-in-chatgpt/</a></li>
</ul>
<h3 id="英語要約">英語要約</h3>
<p>OpenAI introduced a general‑purpose “ChatGPT agent” that can navigate calendars, create slideshows, run code and use connectors like Gmail and GitHub. The agent combines earlier tools, including Operator (browser automation) and Deep Research (web synthesis), and is available to Pro, Plus and Team subscribers. OpenAI claims the agent can perform complex tasks, such as planning a Japanese breakfast or analysing competitors, by autonomously browsing and executing actions.</p>
<h3 id="日本語翻訳">日本語翻訳</h3>
<p>OpenAI は ChatGPT に「ChatGPT agent」という汎用エージェントを追加し、カレンダーの閲覧、スライドの作成、コード実行、Gmail や GitHub との連携などが可能になった。このエージェントは Operator（ブラウザ操作）と Deep Research（ウェブ情報統合）を統合したもので、Pro・Plus・Team プランのユーザーが利用できる。OpenAI によれば、エージェントは日本の朝食を作るための材料購入や競合分析用のスライド作成など複雑なタスクも自律的に実行できる。</p>
<h3 id="感想">感想</h3>
<p>使ってみた感じ、前 OpenAI が出していた Operator よりも高精度な気がする。推論系の LLM をふんだんに使っていて、OpenAI らしいなと思った。</p>
<p>世間の注目度は高いんだけど、これで何ができるかといったら難しいところだなぁと思っている。</p>
<h2 id="meta-hires-two-apple-ai-researchers-after-poaching-their-boss-reuters">Meta hires two Apple AI researchers after poaching their boss (Reuters)</h2>
<h3 id="リンク-1">リンク</h3>
<ul>
<li><a href="https://www.reuters.com/business/retail-consumer/meta-hires-two-apple-ai-researchers-after-poaching-their-boss-bloomberg-reports-2025-07-18/">https://www.reuters.com/business/retail-consumer/meta-hires-two-apple-ai-researchers-after-poaching-their-boss-bloomberg-reports-2025-07-18/</a></li>
</ul>
<h3 id="英語要約-1">英語要約</h3>
<p>Reuters reported that Meta Platforms hired Apple AI researchers Mark Lee and Tom Gunter for its Superintelligence Labs team. Both had recently left Apple; Lee had already started at Meta and Gunter would join soon. The report underscores the competition among big tech firms for talent in artificial intelligence.</p>
<h3 id="日本語翻訳-1">日本語翻訳</h3>
<p>Reuters によると、Meta Platforms は Apple の AI 研究者である Mark Lee 氏と Tom Gunter 氏を Superintelligence Labs チームに採用した。2 人は最近 Apple を退職しており、リー氏はすでに Meta で勤務を開始、ガンター氏もまもなく合流する予定だ。AI 人材を巡る大手企業間の争奪戦が浮き彫りになった。</p>
<h3 id="感想-1">感想</h3>
<p>この AI 人材獲得戦争はどこまで続くんだろう。</p>
<h2 id="meta-taps-connorhayes-as-the-new-head-of-threads-startupnews">Meta taps Connor Hayes as the new head of Threads (StartupNews)</h2>
<h3 id="リンク-2">リンク</h3>
<ul>
<li><a href="https://startupnews.fyi/2025/07/18/meta-taps-connor-hayes-as-the-new-head-of-threads/">https://startupnews.fyi/2025/07/18/meta-taps-connor-hayes-as-the-new-head-of-threads/</a></li>
</ul>
<h3 id="英語要約-2">英語要約</h3>
<p>StartupNews reported that Meta promoted Connor Hayes, previously vice‑president of product for generative AI, to head of the social‑media app Threads. He succeeds Adam Mosseri and will take over in September 2025. The article emphasised that Hayes’ background in generative AI reflects Meta’s focus on integrating AI features into Threads.</p>
<h3 id="日本語翻訳-2">日本語翻訳</h3>
<p>StartupNews は、Meta が生成 AI プロダクト担当副社長だった Connor Hayes 氏を Threads の責任者に昇格させると報じた。Hayes 氏は 2025 年 9 月から Adam Mosseri 氏の後任として就任する。彼が生成 AI の経験を持つことは、Meta が Threads に AI 機能を組み込む戦略を示している。</p>
<h3 id="感想-2">感想</h3>
<p>SNS でも AI が重要になる。これから AI に飲み込まれている。</p>
<h2 id="exclusive-amazons-aws-cloud-computing-unit-cuts-at-least-hundreds-of-jobs-reuters">Exclusive: Amazon’s AWS cloud computing unit cuts at least hundreds of jobs (Reuters)</h2>
<h3 id="リンク-3">リンク</h3>
<ul>
<li><a href="https://www.reuters.com/business/retail-consumer/amazons-aws-cloud-computing-unit-cuts-least-hundreds-jobs-sources-say-2025-07-17/">https://www.reuters.com/business/retail-consumer/amazons-aws-cloud-computing-unit-cuts-least-hundreds-jobs-sources-say-2025-07-17/</a></li>
</ul>
<h3 id="英語要約-3">英語要約</h3>
<p>Reuters reported that Amazon’s AWS division laid off hundreds of employees just weeks after CEO Andy Jassy said adoption of generative AI would reduce headcount. A spokesperson said the cuts were necessary to “optimize resources” while continuing to invest and innovate. Despite strong sales growth, AWS joined other tech firms in announcing layoffs. The article noted that generative AI is increasingly used to write code and automate tasks, reducing reliance on human workers.</p>
<h3 id="日本語翻訳-3">日本語翻訳</h3>
<p>Reuters によると、Amazon のクラウド部門 AWS は数百人規模の人員削減を実施した。CEO の Andy Jassy 氏が生成 AI の導入で人員が削減されると予告してから数週間後のことだった。広報担当者は、リソースを最適化しつつ投資と革新を続けるために必要な措置だと述べた。強い売上成長があるにもかかわらず、AWS は他のテクノロジー企業と同様にレイオフを発表した。記事は、生成 AI がコード作成やタスク自動化に利用され、人的依存が減少していることを指摘している。</p>
<h3 id="感想-3">感想</h3>
<p>売り上げが上がっているであろう AWS でさえも人員削減。AI 導入に対する強い意識が企業をさらに強くする。</p>
<h2 id="nvidia-ai-releases-canaryqwen25b-a-state-of-the-art-asrllm-hybrid-model-marktechpost">NVIDIA AI Releases Canary‑Qwen‑2.5B: A State-of-the-Art ASR‑LLM Hybrid Model (MarkTechPost)</h2>
<h3 id="リンク-4">リンク</h3>
<ul>
<li><a href="https://www.marktechpost.com/2025/07/17/nvidia-ai-releases-canary-qwen-2-5b-a-state-of-the-art-asr-llm-hybrid-model-with-sota-performance-on-openasr-leaderboard/">https://www.marktechpost.com/2025/07/17/nvidia-ai-releases-canary-qwen-2-5b-a-state-of-the-art-asr-llm-hybrid-model-with-sota-performance-on-openasr-leaderboard/</a></li>
</ul>
<h3 id="英語要約-4">英語要約</h3>
<p>NVIDIA released <strong>Canary‑Qwen‑2.5B</strong>, a hybrid model combining a FastConformer speech encoder with a Qwen3‑1.7B language model decoder. It achieved a 5.63 % word‑error rate on Hugging Face’s OpenASR leaderboard and runs 418× faster than real time. The model is open‑source under a CC‑BY license and supports tasks like transcription, summarization and question answering directly from audio. The architecture allows modular replacement of the encoder or decoder and is optimized for various NVIDIA GPUs.</p>
<h3 id="日本語翻訳-4">日本語翻訳</h3>
<p>NVIDIA は、音声認識用 FastConformer エンコーダーと言語モデル Qwen3‑1.7B デコーダーを組み合わせたハイブリッドモデル <strong>Canary‑Qwen‑2.5B</strong> を発表した。Hugging Face の OpenASR ランキングで 5.63 % の語誤り率と、実時間の 418 倍という高速推論を達成した。CC‑BY ライセンスで公開され、音声から直接文字起こし・要約・質疑応答が可能。モジュール構造によりエンコーダーやデコーダーの交換ができ、さまざまな GPU に最適化されている。</p>
<h3 id="感想-4">感想</h3>
<p>メモ。音声系のモデルは全然詳しくないけど OSS だし良さそう。</p> </article>  </main> <footer>© 2025 justy's blog</footer> </body></html>