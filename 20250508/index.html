<!DOCTYPE html><html lang="ja"> <head><meta charset="utf-8"><title>20250508</title><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="alternate" type="application/rss+xml" href="/rss.xml"></head> <body> <header><a href="/">Home</a></header> <main>  <article> <h1 id="20250508">2025/05/08</h1>
<h2 id="meta-perception-language-model-plm-open-vision-language-ai-model-set-to-boost-crypto-ai-tokens-in-2025">Meta Perception Language Model (PLM): Open Vision-Language AI Model Set to Boost Crypto AI Tokens in 2025</h2>
<h3 id="リンク">リンク</h3>
<ul>
<li><a href="https://blockchain.news/flashnews/meta-perception-language-model-plm-open-vision-language-ai-model-set-to-boost-crypto-ai-tokens-in-2025">https://blockchain.news/flashnews/meta-perception-language-model-plm-open-vision-language-ai-model-set-to-boost-crypto-ai-tokens-in-2025</a></li>
</ul>
<h3 id="英語要約">英語要約</h3>
<p>Meta AI unveiled the Perception Language Model (PLM), an open-source, reproducible vision-language model (up to 8 B parameters) aimed at advanced visual understanding. Announced on May 7, PLM comes with datasets, code, and evaluation suites; analysts predict it will invigorate open-source computer-vision research and even drive speculation in AI-related crypto tokens aligned with decentralized AI infrastructure.</p>
<h3 id="日本語翻訳">日本語翻訳</h3>
<p>Meta AI は 5 月 7 日、オープンソースの視覚と言語の統合モデル「Perception Language Model（PLM）」を発表しました（最大 80 億パラメータ）。データセット、学習レシピ、評価ベンチまで公開し、高度な視覚認識タスクを共同研究者が再現・改良できるように設計されています。記事では、オープン CV 研究の加速だけでなく、分散型 AI 基盤と関係の深い暗号資産（RNDR、FET など）への投機的資金流入も指摘されています。</p>
<h3 id="感想">感想</h3>
<p>昨日も話題にあった PLM。
<a href="https://x.com/AIatMeta/status/1920153975921521018">X で Meta が 4 月にあったことをツイートしただけ</a>っぽいんだけど、どう広がっていくのか。そもそも VLM と何が違うのか。</p>
<h2 id="study-introduces-an-ai-agent-that-automates-quantum-chemistry-tasks-from-natural-language-prompts">Study Introduces an AI Agent That Automates Quantum Chemistry Tasks From Natural Language Prompts</h2>
<h3 id="リンク-1">リンク</h3>
<ul>
<li><a href="https://thequantuminsider.com/2025/05/07/study-introduces-an-ai-agent-that-automates-quantum-chemistry-tasks-from-natural-language-prompts/">https://thequantuminsider.com/2025/05/07/study-introduces-an-ai-agent-that-automates-quantum-chemistry-tasks-from-natural-language-prompts/</a></li>
</ul>
<h3 id="英語要約-1">英語要約</h3>
<p>A new paper presents <strong>El Agente Q</strong>, a multi-agent system that couples large language models with quantum-chemistry software to translate plain-English questions into end-to-end computational workflows. Benchmarking on university-level problems shows >87 % task success and in-situ debugging, indicating a path toward autonomous scientific discovery.([Lifeboat Foundation][4])</p>
<h3 id="日本語翻訳-1">日本語翻訳</h3>
<p>LLM と量子化学ソフトを連携させたマルチエージェントシステム「El Agente Q」が公開されました。自然言語クエリを分解し、計算手順を自動生成・実行し、結果解析まで行います。大学レベルの課題で 87%以上の成功率を示し、エラー発生時にはその場でワークフローを自己修正する能力も確認されました。([Lifeboat Foundation][4])</p>
<h3 id="感想-1">感想</h3>
<p>記事の中身を読む感じ、タスクをサブタスクに分けてそれぞれを Agent が実行する中央集権型のマルチエージェントアーキテクチャっぽい。よくある形。
具体的には、Agent は化学データ取得、ファイル処理、構造最適化、基底関数選択、レポート作成のための LaTeX レンダリングなど。
これらは、中央計画 Agent によって統合されていて、中央計画 Agent が計算の進捗状況を追跡・中間結果に基づいて動的にアクションを調整する。</p>
<p>よくある形の LLM 計画型のマルチエージェントなんだけど、配下の Agent をきちんと特定ドメインに対して作るが大事なんだな。当たり前なんだけど。</p> </article>  </main> <footer>© 2025 justy's blog</footer> </body></html>